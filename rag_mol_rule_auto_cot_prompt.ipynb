{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c824ee-810a-4229-8757-630871e670e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "max_N=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5c11d6d-054f-4e8a-b7db-91e53352aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('dataset/qm9_with_mol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d6fd598-a520-4a0e-a926-e6944dd91715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_molecular_weight(input_weight, dataset_df):\n",
    "    filtered_df = dataset_df[(dataset_df['molecular weight']<=input_weight+5) & (dataset_df['molecular weight']>=input_weight-5)]\n",
    "    if len(filtered_df)>max_N:\n",
    "        filtered_df = filtered_df.sample(max_N)\n",
    "    return filtered_df\n",
    "    \n",
    "functional_group_columns = dataset_df.columns[dataset_df.columns.get_loc(\"Hydroxyl\"):dataset_df.columns.get_loc(\"Anhydride\")+1]\n",
    "\n",
    "def process_row(row):\n",
    "    # Basic structure of the JSON object\n",
    "    json_item = {\n",
    "        \"SMILES\": row[\"SMILES\"],\n",
    "        \"molecular weight\": row[\"molecular weight\"]\n",
    "    }\n",
    "\n",
    "    # Computed properties\n",
    "    properties = [\"mu\", \"alpha\", \"homo\", \"lumo\", \"gap\", \"U0\", \"U\", \"H\", \"G\"]\n",
    "    for prop in properties:\n",
    "        if pd.notna(row[prop]):\n",
    "            json_item[prop] = row[prop]\n",
    "\n",
    "    # Functional groups\n",
    "    functional_groups = row[functional_group_columns]\n",
    "    if functional_groups.any():\n",
    "        json_item[\"functional group\"] = functional_groups.index[functional_groups].tolist()\n",
    "\n",
    "    return json_item\n",
    "    \n",
    "def to_reference_text(filtered_df):\n",
    "    plain_text_list = []\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        tmp=[]\n",
    "        for key, value in process_row(row).items():\n",
    "            if isinstance(value, list):\n",
    "                value = \", \".join(value)  # Convert list to string\n",
    "            tmp.append(f\"{key}:{value}\")\n",
    "        plain_text_list.append(\"  \".join(tmp))\n",
    "    reference_text = \"\\n\".join(plain_text_list)\n",
    "    return reference_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499bb7a5-c501-4c72-9ef2-29c7d7622283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "# client = OpenAI(api_key = ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1fd7310-0c59-4567-bec6-37da12400351",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testset.jsonl', 'r') as file:\n",
    "    json_line = file.readlines()\n",
    "\n",
    "gt_list = []\n",
    "property_list = []\n",
    "for i in json_line:\n",
    "    item = json.loads(i)\n",
    "    gt_list.append(item['SMILES'])\n",
    "    item.pop('SMILES')\n",
    "    property_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c1a4fd-1205-4bc2-8189-7fbfbd4b4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompt(properties):\n",
    "    tmp = []\n",
    "    for key, value in properties.items():\n",
    "        if isinstance(value, list):\n",
    "            value = \", \".join(value)  # Convert list to string\n",
    "        tmp.append(f\"{key}: {value}\")\n",
    "    plain_property = \"\\n\".join(tmp)\n",
    "    \n",
    "    with open('rag_mol_prompt_user.txt', 'r') as f:\n",
    "        user_prompt = f.read()\n",
    "    user_prompt = user_prompt.replace('{PROPERTIES}', plain_property)\n",
    "    \n",
    "\n",
    "    mol_weight = float(properties['molecular weight'].replace('g/mol', ''))\n",
    "    filtered_dataset = filter_molecular_weight(mol_weight, dataset_df=dataset_df)\n",
    "\n",
    "    reference_text = to_reference_text(filtered_dataset)\n",
    "\n",
    "    with open('rag_mol_rule_auto_cot_prompt_assistant.txt', 'r') as f:\n",
    "        assi_prompt = f.read()\n",
    "    assi_prompt = assi_prompt.replace('{QM9_REFERENCE}', reference_text)\n",
    "\n",
    "    return user_prompt, assi_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "038f6a23-a586-4c88-9df6-f2bf65feed59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [11:38<00:00, 13.97s/it]\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "top10_list = []\n",
    "\n",
    "for gt, properties in tqdm(zip(gt_list, property_list), total=len(gt_list)):\n",
    "\n",
    "    user_prompt, assi_prompt = prepare_prompt(properties)\n",
    "        \n",
    "    completion = client.chat.completions.create(\n",
    "          model=model,\n",
    "          temperature=0,\n",
    "          messages=[{\"role\": \"user\", \"content\": user_prompt},\n",
    "                   {\"role\": \"system\", \"content\": assi_prompt}])\n",
    "    if gt in completion.choices[0].message.content:\n",
    "        top10_list.append(1)\n",
    "    else:\n",
    "        top10_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "751834f8-c8d3-4c2f-a15b-63664b6a02c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:gpt-3.5-turbo  Accuracy:0.2400\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:%s  Accuracy:%.4f\" %(model, sum(top10_list)/50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94da073a-fe31-481f-92e6-cb5618474c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [22:15<00:00, 26.70s/it]\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4-turbo\"\n",
    "top10_list = []\n",
    "\n",
    "for gt, properties in tqdm(zip(gt_list, property_list), total=len(gt_list)):\n",
    "\n",
    "    user_prompt, assi_prompt = prepare_prompt(properties)\n",
    "        \n",
    "    completion = client.chat.completions.create(\n",
    "          model=model,\n",
    "          temperature=0,\n",
    "          messages=[{\"role\": \"user\", \"content\": user_prompt},\n",
    "                   {\"role\": \"system\", \"content\": assi_prompt}])\n",
    "    if gt in completion.choices[0].message.content:\n",
    "        top10_list.append(1)\n",
    "    else:\n",
    "        top10_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06a54133-e14d-4695-8621-55a279dc642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:gpt-4-turbo  Accuracy:0.2600\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:%s  Accuracy:%.4f\" %(model, sum(top10_list)/50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f006ec-680b-4704-b926-c55de8188f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [21:29<00:00, 25.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:vicuna-7b-v1.5-16k  Accuracy:0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"EMPTY\"\n",
    "openai.base_url = \"http://localhost:8000/v1/\"\n",
    "\n",
    "model = \"vicuna-7b-v1.5-16k\"\n",
    "top10_list = []\n",
    "\n",
    "for gt, properties in tqdm(zip(gt_list, property_list), total=len(gt_list)):\n",
    "\n",
    "    user_prompt, assi_prompt = prepare_prompt(properties)\n",
    "        \n",
    "    completion = openai.chat.completions.create(\n",
    "          model=model,\n",
    "          temperature=0,\n",
    "          max_tokens=500,\n",
    "          messages=[{\"role\": \"user\", \"content\": user_prompt},\n",
    "                   {\"role\": \"system\", \"content\": assi_prompt}])\n",
    "    if gt in completion.choices[0].message.content:\n",
    "        top10_list.append(1)\n",
    "    else:\n",
    "        top10_list.append(0)\n",
    "\n",
    "print(\"Model:%s  Accuracy:%.4f\" %(model, sum(top10_list)/50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db9d994d-565b-4b29-83ea-765217a796f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [33:59<00:00, 40.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:vicuna-13b-v1.5-16k  Accuracy:0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"EMPTY\"\n",
    "openai.base_url = \"http://localhost:8001/v1/\"\n",
    "\n",
    "model = \"vicuna-13b-v1.5-16k\"\n",
    "top10_list = []\n",
    "\n",
    "for gt, properties in tqdm(zip(gt_list, property_list), total=len(gt_list)):\n",
    "\n",
    "    user_prompt, assi_prompt = prepare_prompt(properties)\n",
    "        \n",
    "    completion = openai.chat.completions.create(\n",
    "          model=model,\n",
    "          temperature=0,\n",
    "          max_tokens=500,\n",
    "          messages=[{\"role\": \"user\", \"content\": user_prompt},\n",
    "                   {\"role\": \"system\", \"content\": assi_prompt}])\n",
    "    if gt in completion.choices[0].message.content:\n",
    "        top10_list.append(1)\n",
    "    else:\n",
    "        top10_list.append(0)\n",
    "\n",
    "print(\"Model:%s  Accuracy:%.4f\" %(model, sum(top10_list)/50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236ecd6-0147-4532-9469-ea3f0dc3f43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
